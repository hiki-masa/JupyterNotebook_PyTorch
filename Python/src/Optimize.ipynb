{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b64f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3e213",
   "metadata": {},
   "source": [
    "# パラメータ更新\n",
    "注：事前に[自動微分](./AutoGrad.ipynb)を理解してから、本章を学習したほうが良い<br>\n",
    "- `torch.optim` : SGDなどの複数のオプティマイザが含まれていて、逆伝搬の際に`Parameter`\n",
    "の重みを更新する<br>\n",
    "最適化手法には以下の種類がある\n",
    "    - SGD\n",
    "    - Adagrad\n",
    "    - RMSprop\n",
    "    - Adadelta\n",
    "    - Adam\n",
    "    - AdamW\n",
    "\n",
    "今回は一番シンプルなSGDについて説明する\n",
    "\n",
    "## SGD : Stochastic Gradient Descentとは\n",
    "確率的勾配降下法と呼ばれ、パラメータの更新手法のことである\n",
    "### 勾配降下法\n",
    "1. 適当に初期点を決める\n",
    "2. 現在の地点における降下方向を計算する<br>\n",
    "降下方向：$-\\frac{\\partial L}{\\partial w}$\n",
    "3. 降下方向に進む<br>\n",
    "$w = w - \\eta \\frac{\\partial L}{\\partial w}$<br>\n",
    "$b = b - \\eta \\frac{\\partial L}{\\partial b}$<br>\n",
    "2 に戻り、値が変化しなくなるまで繰り返す\n",
    "\n",
    "### 確率的勾配降下法\n",
    "勾配降下法の場合、データ数$N$が大きくなると、$\\frac{\\partial L}{\\partial w}$などの計算が非常に大変になる<br>\n",
    "そこで、すべてのデータを使用するのではなく、ランダムに選んだ一部のデータのみを使用\n",
    "- `optim.SGD(params, lr, momentum=0, dampening=0, weight_decay=0, nesterov=False, maximize=False, foreach=None)`\n",
    "    - params : 最適化するパラメータ\n",
    "    - lr : 学習率\n",
    "- `optimizer.step()` : 最適化ステップ（パラメータ更新）を実行している<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f5c4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight : 0.13374245166778564\n",
      "Initial bias   : -0.08374321460723877\n",
      "-------------------\n",
      "Update weight  : 0.20930258929729462\n",
      "Update bias    : -0.062378183007240295\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5]).unsqueeze(1).float()\n",
    "t = torch.tensor([5, 8, 11, 14, 17]).unsqueeze(1).float()\n",
    "\n",
    "linear = nn.Linear(1, 1)\n",
    "MSE = nn.MSELoss()\n",
    "# 最適化手法の指定\n",
    "optimizer = optim.SGD(linear.parameters(), lr = 1e-3)\n",
    "\n",
    "# weight, biasの初期値を確認\n",
    "print(f\"Initial weight : {linear.weight.item()}\")\n",
    "print(f\"Initial bias   : {linear.bias.item()}\")\n",
    "\n",
    "y = linear(x)\n",
    "L = MSE(y, t)\n",
    "\n",
    "L.backward()\n",
    "optimizer.step()\n",
    "print(\"-------------------\")\n",
    "print(f\"Update weight  : {linear.weight.item()}\")\n",
    "print(f\"Update bias    : {linear.bias.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ccefb",
   "metadata": {},
   "source": [
    "# パラメータ推定\n",
    "`optimizer.zero_grad()` : PyTorchの仕様で勾配（$\\frac{\\partial L}{\\partial w}$や$\\frac{\\partial L}{\\partial b}$）が既存の値に加算されるので、勾配値をリセットするために使用<br>\n",
    "今回の場合、$x = [1, 2, 3, 4, 5]$で$t = [5, 8, 11, 14, 17]$なので、$y = 3x + 2$となるとき、$y$と$t$の差が最小になる<br>\n",
    "推定結果は$weight$・$bias$ともに、最適化されている（差が最小になる値に変化している）のが確認できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "332e614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt weight     : 3.017526865005493\n",
      "Opt bias       : 1.9367316961288452\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5]).unsqueeze(1).float()\n",
    "t = torch.tensor([5, 8, 11, 14, 17]).unsqueeze(1).float()\n",
    "\n",
    "linear = nn.Linear(1, 1)\n",
    "MSE = nn.MSELoss()\n",
    "optimizer = optim.SGD(linear.parameters(), lr = 1e-3)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    y = linear(x)\n",
    "    L = MSE(y, t)\n",
    "    optimizer.zero_grad()\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Opt weight     : {linear.weight.item()}\")\n",
    "print(f\"Opt bias       : {linear.bias.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
